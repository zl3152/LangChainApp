{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain\n",
    "%pip install -qU openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = \"blah\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using FewShotPrompt\n",
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first initialize the large language model\n",
    "llm = OpenAI(\n",
    "\topenai_api_key=api_key,\n",
    "\tmodel_name=\"text-davinci-003\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using FewShotPrompt\n",
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "#Set up the examples \n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Translate the following English quote to classical Chinese: 'To be or not to be, that is the question.'\",\n",
    "        \"answer\": \"生存与否，是个问题。\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Translate the following classical Chinese quote to English: '己所不欲，勿施于人'\",\n",
    "        \"answer\": \"Do not do unto others what you would not have them do unto you.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Translate the following English quote to classical Chinese: 'The best preparation for tomorrow is doing your best today.'\",\n",
    "        \"answer\": \"凡事预则立，不预则废。\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Translate the following classical Chinese quote to English: '知之为知之，不知为不知，是知也'\",\n",
    "        \"answer\": \"To know when you know, and to know when you do not know, that is wisdom.\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"query\": \"Translate the following English quote to classical Chinese: 'The only way to do great work is to love what you do.'\",\n",
    "        \"answer\": \"唯有热爱所做，始能成就伟业。\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# create a example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI assistant. \n",
    "The assistant accurately translates English to Chinese, or Chinese to English text\n",
    "while preserving the original style and meaning. \n",
    "Here is an example:\n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 生存与否，是个问题。\n"
     ]
    }
   ],
   "source": [
    "query = \"To be or not to be, that is the question\"\n",
    "\n",
    "print(llm(few_shot_prompt_template.format(query=query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=50  # this sets the max length that examples should be\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create the few shot prompt template\n",
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # use example_selector instead of examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To be or not to be, that is the question.\n"
     ]
    }
   ],
   "source": [
    "llm.temperature = 1.0\n",
    "print(llm(dynamic_prompt_template.format(query=\"生存与否，是个问题\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
